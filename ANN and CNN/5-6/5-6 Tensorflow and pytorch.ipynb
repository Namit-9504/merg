{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f4dfb5b-e244-4a7d-818a-a012cc75c67e",
   "metadata": {},
   "source": [
    "## information notebook is present in data science/pwnotes/5-6\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e23b774-7d4f-4faf-8bb4-8c1521a6e2ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88afb6d8-7209-4773-82fa-656e5764184c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (489.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m489.8/489.8 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting wrapt<1.15,>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Collecting tensorboard<2.15,>=2.14\n",
      "  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting ml-dtypes==0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.1)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.59.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting keras<2.15,>=2.14.0\n",
      "  Downloading keras-2.14.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m71.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m52.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.15,>=2.14.0\n",
      "  Downloading tensorflow_estimator-2.14.0-py2.py3-none-any.whl (440 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.11)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.34.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.15,>=2.14->tensorflow) (2.28.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/94.2 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m78.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-2.3.7-py3-none-any.whl (242 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.2/242.2 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.23.2-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.0/182.0 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.15,>=2.14->tensorflow) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.15,>=2.14->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.15,>=2.14->tensorflow) (3.2.2)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, opt-einsum, ml-dtypes, markdown, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.23.2 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.59.0 keras-2.14.0 libclang-16.0.6 markdown-3.4.4 ml-dtypes-0.2.0 opt-einsum-3.3.0 pyasn1-0.5.0 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.14.1 tensorboard-data-server-0.7.1 tensorflow-2.14.0 tensorflow-estimator-2.14.0 tensorflow-io-gcs-filesystem-0.34.0 termcolor-2.3.0 werkzeug-2.3.7 wrapt-1.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ae3561c-80bf-4290-a4b7-28d0ab25ae0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (2.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3046d9f6-422f-4240-860e-551921d64d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version 2.14.0\n",
      "Eager Execution is : True\n",
      "keras version : 2.14.0\n"
     ]
    }
   ],
   "source": [
    "## Version Check\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "print('tensorflow version {}'.format(tf.__version__))\n",
    "print('Eager Execution is : {}'.format(tf.executing_eagerly()))\n",
    "print('keras version : {}'.format(keras.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "292d6426-c0a0-462b-afbc-25ab37896f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=42>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ineuron=tf.constant(42)\n",
    "ineuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1dffa783-c145-4ee3-8a6d-5bf3d681d65e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ineuron.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb9d066d-974f-41ff-b756-249c183c280f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ineuron1=tf.constant(1,dtype=tf.int64)\n",
    "ineuron1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1b0220b2-de2c-410e-956a-441edb682d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "ineuron_X=tf.constant([(2,2),(5,5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "865d61f6-d54c-4639-b57e-04d4a5eed260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 2]\n",
      " [5 5]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(ineuron_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0993a562-0e79-488c-ab72-5c4a8fbd15a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2]\n",
      " [5 5]] \n",
      "\n",
      "(2, 2) \n",
      "\n",
      "<dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "print(ineuron_X.numpy(),'\\n')\n",
    "print(ineuron_X.shape,'\\n')\n",
    "print(ineuron_X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c2ec768-0f34-4d11-a900-33f4a0cff666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## genrrating Constants \n",
    "print(tf.ones(shape=(2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a40e9216-6ee1-4ee9-8cb4-49b0de2a91aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]], shape=(2, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf.zeros(shape=(2,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efe9c455-f552-43ef-a4e4-c75966d2053e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[5 7 9]\n",
      " [5 7 9]], shape=(2, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "## Adding two Constansts \n",
    "con1=tf.constant([[4,5,6],[4,5,6]])\n",
    "con2=tf.constant([[1,2,3],[1,2,3]])\n",
    "result=tf.add(con1,con2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ce23c35-5c28-4dba-b48a-edecc26a9c1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 8.338776 , 11.090475 ],\n",
       "       [ 6.5484014,  6.731309 ]], dtype=float32)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Declearring Constants Randomly \n",
    "## using Normal Distributtion\n",
    "tf.random.normal(shape=(2,2),mean=5,stddev=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3440ba42-48ef-4485-a919-6e7599897865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 3), dtype=int64, numpy=\n",
       "array([[4, 0, 4],\n",
       "       [2, 8, 9],\n",
       "       [9, 3, 2]])>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## using uniform Distribusion\n",
    "tf.random.uniform(shape=(3,3),minval=0,maxval=10,dtype=tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00f38f26-37c0-4177-be53-4e86335ea68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## variables in tensor\n",
    "var0 = 24 # python Variable\n",
    "var1 = tf.Variable(42) ## rank 0 tensor\n",
    "var2 = tf.Variable([[[1.,2.,3.],[4.,5.,6.]],[[7.,8.,9.],[2.,5.,6]]]) ## rank 3 tensor\n",
    "\n",
    "### Rank is basically no of indices or the no of dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b2f50862-824c-4f83-b9c3-512e6cdbeffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24,\n",
       " <tf.Variable 'Variable:0' shape=() dtype=int32, numpy=42>,\n",
       " <tf.Variable 'Variable:0' shape=(2, 2, 3) dtype=float32, numpy=\n",
       " array([[[1., 2., 3.],\n",
       "         [4., 5., 6.]],\n",
       " \n",
       "        [[7., 8., 9.],\n",
       "         [2., 5., 6.]]], dtype=float32)>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var0,var1,var2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5a722dd1-a023-4377-950d-3d418d86ffe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=52>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Reassigning the values\n",
    "variable1=tf.Variable(52)\n",
    "variable1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98357f12-0eb1-4c1a-b0b7-c6e23832d64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=() dtype=int32, numpy=34>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variable1.assign(34)\n",
    "variable1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21fc5de5-03de-4544-952f-9870d42678a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor=tf.Variable([[[1,2,3],[4,5,6]],[[7,8,9],[10,11,12]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3b44f222-e6e1-453a-9c25-f2e8df749ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor1=tf.reshape(tensor,(2,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a0145a0-3774-4be8-9cad-e935356308a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 6), dtype=int32, numpy=\n",
       "array([[ 1,  2,  3,  4,  5,  6],\n",
       "       [ 7,  8,  9, 10, 11, 12]], dtype=int32)>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59491c08-278c-4a61-a67c-345f5c2c4447",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor2=tf.reshape(tensor,(1,12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dee3f5f-55ec-48cf-bd14-ba61a71a29b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 12), dtype=int32, numpy=array([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]], dtype=int32)>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0c8244e-d0a7-4789-9b19-2e81ad019dbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "\n",
      "\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "\n",
      "\n",
      "tf.Tensor(2, shape=(), dtype=int32)\n",
      "\n",
      "\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "## How to Know the ranking of the Tensor\n",
    "print(tf.rank(tensor))\n",
    "print('\\n')\n",
    "print(tf.rank(tensor1))\n",
    "print('\\n')\n",
    "print(tf.rank(tensor2))\n",
    "print('\\n')\n",
    "## to get the direct value of rank use numpy\n",
    "print(tf.rank(tensor).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373be24c-5f47-4e84-b9d0-11f1af798736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5d80f5bf-55ad-4625-8504-6a53e4d0e0ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=9>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor3 = tensor[1,0,2]\n",
    "tensor3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d1ae063-f9d7-4a0f-89dd-ca76237e805a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 1  2  3]\n",
      "  [ 4  5  6]]\n",
      "\n",
      " [[ 7  8  9]\n",
      "  [10 11 12]]]\n"
     ]
    }
   ],
   "source": [
    "print(tensor.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1561f50a-e036-4551-9449-18915177ae86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## finding size of an array is bascially a no of elements in the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c7697ae-4be6-45b4-b575-20f5b41d7a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_size=tf.size(tensor).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a1cbd80-c46c-4db4-8919-fcf3dec6b082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0af0792c-a5ef-4f18-b856-8515e46f1275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[16.841389 12.927839]\n",
      " [20.863482 19.250078]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[27.939213 20.781715]\n",
      " [19.003704 25.014366]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[44.7806   33.709557]\n",
      " [39.867188 44.264442]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[2005.3022 1136.3342]\n",
      " [1589.3926 1959.3408]], shape=(2, 2), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[2.8052278e+19 4.3638962e+14]\n",
      " [2.0611022e+17 1.6741837e+19]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## some Mathametical operations\n",
    "a=tf.random.normal(shape=(2,2),mean=20,stddev=5)\n",
    "b=tf.random.normal(shape=(2,2),mean=20,stddev=5)\n",
    "c=a+b\n",
    "d=tf.square(c)\n",
    "e=tf.exp(c)\n",
    "print(a)\n",
    "print(b)\n",
    "print(c)\n",
    "print(d)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "05582035-5834-4c0c-93ca-aca2e6f850c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
       "array([[[  1,   4,   9],\n",
       "        [ 16,  25,  36]],\n",
       "\n",
       "       [[ 49,  64,  81],\n",
       "        [100, 121, 144]]], dtype=int32)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor*tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "872c5909-4ad4-4ff3-9ec2-92a4073a9cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 2, 3) dtype=int32, numpy=\n",
       "array([[[ 1,  2,  3],\n",
       "        [ 4,  5,  6]],\n",
       "\n",
       "       [[ 7,  8,  9],\n",
       "        [10, 11, 12]]], dtype=int32)>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e31d92c7-aae0-4a54-acc1-add9c19d197a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor4=tensor*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1f14414-38fd-48cc-a49b-0b60edc5de22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2, 3), dtype=int32, numpy=\n",
       "array([[[ 5, 10, 15],\n",
       "        [20, 25, 30]],\n",
       "\n",
       "       [[35, 40, 45],\n",
       "        [50, 55, 60]]], dtype=int32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e1b60590-1ca2-4fb2-9f2b-5d21313bfad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 1  2  3  4  5  6]\n",
      " [ 7  8  9 10 11 12]], shape=(2, 6), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 1.  2.  3.  4.  5.  6.]\n",
      " [ 7.  8.  9. 10. 11. 12.]], shape=(2, 6), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "## Tensor casting\n",
    "print(tensor1)\n",
    "i=tf.cast(tensor1,dtype=tf.float32)\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "79784bd9-0253-45c7-8fb0-41cf70163b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "j=tf.cast(tf.constant(4.9),dtype=tf.int32).numpy()\n",
    "print(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "790428a4-0c13-4095-a887-8996213fb1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[1, 2, 3, 6, 5], [], [23, 26, 52], [1], [0, 223, 22, 2222, 22]]>\n",
      "tf.Tensor([1 2 3 6 5], shape=(5,), dtype=int32)\n",
      "tf.Tensor([], shape=(0,), dtype=int32)\n",
      "tf.Tensor([23 26 52], shape=(3,), dtype=int32)\n",
      "tf.Tensor([1], shape=(1,), dtype=int32)\n",
      "tf.Tensor([   0  223   22 2222   22], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "## Ragged Tensor it inclues any shapes of row in tensor\n",
    "ragged=tf.ragged.constant([[1,2,3,6,5],[],[23,26,52],[1],[0,223,22,2222,22]])\n",
    "print(ragged)\n",
    "print(ragged[0,:])\n",
    "print(ragged[1,:])\n",
    "print(ragged[2,:])\n",
    "print(ragged[3,:])\n",
    "print(ragged[4,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29f019a1-c40b-495f-933f-69c4ea7a2d77",
   "metadata": {},
   "outputs": [],
   "source": [
    "## finding squared difference between tensor\n",
    "varX=[1,2,3,6,5,4,6]\n",
    "varY=5\n",
    "varz=tf.math.squared_difference(varX,varY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b224357b-b2bc-47b9-a129-0e1291d86189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(7,), dtype=int32, numpy=array([16,  9,  4,  1,  0,  1,  1], dtype=int32)>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "varz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "acc1609d-2b9c-4a42-8c1c-6b192a1250ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=3.5>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### finding Mean of tensor\n",
    "numbers=tf.constant([[1.,2.],[3.,4.],[5.,6.]])\n",
    "tf.reduce_mean(numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b0b63804-cd73-4258-92b4-82da56c336d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([3., 4.], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## finding mean alongs the columns \n",
    "tf.reduce_mean(numbers,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dabcc045-523d-4be0-8c42-288153ded1f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 2), dtype=float32, numpy=array([[3., 4.]], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### while columns mean we loseing some dimensions to overcome these we use keepdim=True\n",
    "tf.reduce_mean(numbers,axis=0,keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7ffd3927-10a0-4157-bb75-153206faffe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.5, 3.5, 5.5], dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## finding mean alongs the rows\n",
    "tf.reduce_mean(numbers,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6510fb46-e067-4598-be3f-d13414d6048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setting seed it is like a random state by setting a seed we can regenrate the same set of data again and again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4abf75d9-c948-48d5-bbfd-03ca21aeb06a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 2), dtype=float32, numpy=\n",
       "array([[13.471383,  9.830491],\n",
       "       [ 9.815726, 10.357299],\n",
       "       [ 6.684596, 10.861412]], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.random.normal(shape=(3,2),mean=10,stddev=2,dtype=tf.float32,seed=None ,name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "71d1624f-c4de-444f-aef9-9739fd886ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seed helps us to regenrate the random value which we are genrating previous one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "56572d3a-c651-49e5-9b97-ba0e1b72af34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting the seed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86ee6307-9d15-48a7-a7c0-16778ade27d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.5229472   0.66954476 -0.6424697   1.4300429   0.5867822 ]\n",
      " [ 0.4392982   0.06769665  1.4841088  -0.10583612  1.7886113 ]\n",
      " [-1.3436369   0.1916718   0.1465998  -1.2674419  -1.0966402 ]], shape=(3, 5), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 0.35981855  1.0180439  -2.0297976 ]\n",
      " [-0.7807032   2.6000936   0.6251627 ]\n",
      " [ 1.5736731  -1.5090868  -0.08556824]\n",
      " [-0.27837607 -0.00504523  1.2153692 ]], shape=(4, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(11)\n",
    "ran1=tf.random.normal(shape=(3,5))\n",
    "ran2=tf.random.normal(shape=(4,3))\n",
    "print(ran1)\n",
    "print(ran2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4358901a-c035-4ef1-8c1b-62735adc6fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([  2  11   5  42   7  19  -6 -11  29], shape=(9,), dtype=int32)\n",
      "index of max :3\n",
      "maximum number is : 42\n",
      "index of max :7\n",
      "maximum number is : -11\n",
      "tf.Tensor(\n",
      "[[  2  11   5]\n",
      " [ 42   7  19]\n",
      " [ -6 -11  29]], shape=(3, 3), dtype=int32)\n",
      "In t6 columnwise Index of maximum number is [1 0 2] \n",
      "In t6 columnwise Index of minimum number is [0 1 1] \n",
      "In t6 rowwise Index of maximum number is [2 2 0] \n",
      "In t6 rowwise Index of minimum number is [1 0 2] \n"
     ]
    }
   ],
   "source": [
    "t5 = tf.constant([2,11,5,42,7,19,-6,-11,29])\n",
    "print(t5)\n",
    "\n",
    "i = tf.argmax(input=t5)\n",
    "print(f\"index of max :{i}\")\n",
    "print(\"maximum number is :\",t5[i].numpy())\n",
    "\n",
    "j = tf.argmin(input=t5)\n",
    "print(f\"index of max :{j}\")\n",
    "print(\"maximum number is :\",t5[j].numpy())\n",
    "\n",
    "t6=tf.reshape(t5,[3,3])\n",
    "print(t6)\n",
    "\n",
    "i = tf.argmax(input=t6,axis=1).numpy()\n",
    "print(f\"In t6 columnwise Index of maximum number is {i} \")\n",
    "\n",
    "i = tf.argmin(input=t6,axis=1).numpy()\n",
    "print(f\"In t6 columnwise Index of minimum number is {i} \")\n",
    "\n",
    "i = tf.argmin(input=t6,axis=0).numpy()\n",
    "print(f\"In t6 rowwise Index of maximum number is {i} \")\n",
    "\n",
    "i = tf.argmax(input=t6,axis=0).numpy()\n",
    "print(f\"In t6 rowwise Index of minimum number is {i} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "592ca1c7-016f-4ad3-8713-3d24493d4f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving and restoring tensor values using a checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7dd4846-587c-491a-9139-504375d80655",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'Variable:0' shape=(2, 5) dtype=int32, numpy=\n",
      "array([[0, 0, 0, 0, 0],\n",
      "       [0, 0, 0, 0, 0]], dtype=int32)>\n",
      "<tf.Variable 'Variable:0' shape=(2, 5) dtype=int32, numpy=\n",
      "array([[ 1,  2,  3,  4,  5],\n",
      "       [ 7,  8,  9, 10, 11]], dtype=int32)>\n"
     ]
    }
   ],
   "source": [
    "variable = tf.Variable([[1,2,3,4,5],[7,8,9,10,11]])\n",
    "checkpoint=tf.train.Checkpoint(var=variable)\n",
    "save_path=checkpoint.save('./vars')\n",
    "variable.assign([[0,0,0,0,0],[0,0,0,0,0]])\n",
    "print(variable)\n",
    "checkpoint.restore(save_path)\n",
    "print(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c8397de-f86f-447c-9339-d6182ac21e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "## use of tf.function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a21061bc-359d-4866-a99b-4dd4813d57da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=109.0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f1(x,y):\n",
    "    return(tf.reduce_mean(input_tensor=tf.multiply(x**2 ,5 )+y**2))\n",
    "\n",
    "x=tf.constant([4.,-5.])\n",
    "y=tf.constant([2.,3.])\n",
    "\n",
    "f1(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f19e680-eb3b-4575-8baf-e0beb6cea99a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculate the Gradent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2ebad104-0777-49b8-8cdb-f47952dfe57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.  1.]\n",
      " [ 1. -1.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a=tf.random.normal(shape=(2,2))\n",
    "b=tf.random.normal(shape=(2,2))\n",
    "\n",
    "with tf.GradientTape() as tape:\n",
    "    tape.watch(a)\n",
    "    c=tf.sqrt(tf.square(a),tf.square(b))\n",
    "    dc_da= tape.gradient(c,a) ## Calculating Gradient \n",
    "    print(dc_da)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8ccb201a-1f4f-4931-a0c3-a09beede14e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[-1.  1.]\n",
      " [ 1. -1.]], shape=(2, 2), dtype=float32)\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as Outer_tape:\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(a)\n",
    "        c=tf.sqrt(tf.square(a),tf.square(b))\n",
    "        dc_da= tape.gradient(c,a) ## Calculating Gradient \n",
    "        print(dc_da)\n",
    "        d2c_da2 = Outer_tape.gradient(dc_da,a)  ## calculating second Derivative\n",
    "        print(d2c_da2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86c89e3-f255-4a2f-bb6c-6a6b3e7ea938",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af0d8c3e-f918-40b1-883c-2041228159fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch) (4.4.0)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (2.8.8)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.11.1)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m54.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.0.0\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m30.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.12.4-py3-none-any.whl (11 kB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.38.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (65.5.1)\n",
      "Collecting cmake\n",
      "  Downloading cmake-3.27.5-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.1/26.1 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting lit\n",
      "  Downloading lit-17.0.1.tar.gz (154 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.7/154.7 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.2.1)\n",
      "Building wheels for collected packages: lit\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-17.0.1-py3-none-any.whl size=93254 sha256=8edab71bc9c4d6b0ccceb214436722c5449e491ba44705be99d3d277d29f8e55\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/6c/2e/a0/43cf08d34bff019910a37a904aea9d775a5dab15e722e429d5\n",
      "Successfully built lit\n",
      "Installing collected packages: lit, cmake, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, filelock, nvidia-cusolver-cu11, nvidia-cudnn-cu11, triton, torch\n",
      "Successfully installed cmake-3.27.5 filelock-3.12.4 lit-17.0.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 torch-2.0.1 triton-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5cef7f0-cc32-452c-84ab-ecc7d94fafef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8a84a4f-b76e-4243-a1e6-f87572162a90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1=torch.tensor(4.)\n",
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c658dab1-382f-47c1-b557-4bce7e719ede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "984c1906-1d9a-4fff-87ac-ffa52db1ce19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vector or 1d array\n",
    "t2 = torch.tensor([1,2,3,4,5,6])\n",
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e818e4f1-a7ad-4944-b78d-bf071eb78cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.,  6.],\n",
       "        [ 7.,  8.],\n",
       "        [ 9., 10.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2 dimensional array or matrix\n",
    "t3 = torch.tensor([[5.,6.],[7.,8.],[9.,10.]])\n",
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c19a70fc-e302-41c9-ab90-a9f734f31dc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[11, 12, 13],\n",
       "         [14, 15, 16]],\n",
       "\n",
       "        [[17, 18, 19],\n",
       "         [20, 21, 22]]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multidimensional array\n",
    "t4 = torch.tensor([[[11,12,13],[14,15,16]],[[17,18,19],[20,21,22]]])\n",
    "t4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b6e46db-33b5-4850-a3f9-235501aa9b2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t1)\n",
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66ab7924-ec61-47d3-b416-caf761f302e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5, 6])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t2)\n",
    "t2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ebdcc03a-95cd-4dea-b356-b32706f9580e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t3)\n",
    "t3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f1c5627-8d2a-42e8-9c00-d8bba5a2c61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[11, 12, 13],\n",
      "         [14, 15, 16]],\n",
      "\n",
      "        [[17, 18, 19],\n",
      "         [20, 21, 22]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t4)\n",
    "t4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3db3054f-bdc0-4999-b290-481cbe68bc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.), tensor(5., requires_grad=True), tensor(6., requires_grad=True))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor(4.)\n",
    "#\"requires_grad\" if this parameter we set it as a true then we can differeciate any expression with repect to that variable\n",
    "w = torch.tensor(5.,requires_grad=True)\n",
    "b = torch.tensor(6.,requires_grad=True)\n",
    "x,w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b047bd60-bed1-4bec-91dd-cac9a06b3de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(26., grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Consider we have an expression or an Arithmetic operation\n",
    "y = w * x + b\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c69cf173-ab11-4007-92be-2ab2141cbb59",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward() ### it finds all the possible derivatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70d50e38-cbf4-421d-bd3e-157d85e50192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad05eed0-4af3-4556-b52b-6a12edf00ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.)\n"
     ]
    }
   ],
   "source": [
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2fa499c-b8dc-48ff-a1b9-d2b57d0a70f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "193defdd-50b4-480b-9f58-e1b9b89a164f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Functions in Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e204aaf-df23-462f-94d3-581b79ad0bd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[42, 42],\n",
      "        [42, 42],\n",
      "        [42, 42]])\n"
     ]
    }
   ],
   "source": [
    "## Creating a tensor which is full with one same element\n",
    "t6 = torch.full((3,2),42)\n",
    "print(t6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f61803e8-7fdf-41ce-8155-5ad2bf4a4c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[42., 42.],\n",
      "        [42., 42.],\n",
      "        [42., 42.],\n",
      "        [ 5.,  6.],\n",
      "        [ 7.,  8.],\n",
      "        [ 9., 10.]])\n"
     ]
    }
   ],
   "source": [
    "## Concatinate \n",
    "t7 = torch.concat([t6,t3])\n",
    "print(t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "25d87032-2916-42f7-bccc-83ce1524104b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9165, -0.9165],\n",
      "        [-0.9165, -0.9165],\n",
      "        [-0.9165, -0.9165],\n",
      "        [-0.9589, -0.2794],\n",
      "        [ 0.6570,  0.9894],\n",
      "        [ 0.4121, -0.5440]])\n"
     ]
    }
   ],
   "source": [
    "## Compute the sin of each element of a tensor\n",
    "t8 = torch.sin(t7)\n",
    "print(t8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c2ac0786-68af-4d72-ab32-a9949c1daaa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.9165, -0.9165],\n",
      "         [-0.9165, -0.9165]],\n",
      "\n",
      "        [[-0.9165, -0.9165],\n",
      "         [-0.9589, -0.2794]],\n",
      "\n",
      "        [[ 0.6570,  0.9894],\n",
      "         [ 0.4121, -0.5440]]])\n"
     ]
    }
   ],
   "source": [
    "### changing the shape of tensor \n",
    "t9 = t8.reshape(3,2,2)\n",
    "print(t9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "748a0252-8dbc-4165-ba03-68a30118c3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Connection with numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "44ec556d-bfcc-4843-b456-c523f770ba63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "185b500c-a8a6-420f-a53e-5ba897a8e807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 6. 9.]\n",
      " [2. 4. 5.]]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[3.,6.,9.],[2.,4.,5.]])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f40a78db-d1e2-49aa-8e53-13245dfe69c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 6., 9.],\n",
      "        [2., 4., 5.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# from numpy to torch\n",
    "y = torch.from_numpy(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c7b1250-e548-49ca-b424-21599cd8022a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dtype('float64'), torch.float64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtype , y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "73e17576-d30a-41af-92cc-7b8e323760f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3. 6. 9.]\n",
      " [2. 4. 5.]]\n"
     ]
    }
   ],
   "source": [
    "# from torch to numpy\n",
    "z = y.numpy()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0505cf3-6783-4a90-8037-c64aff352b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1c94afa-0db7-427e-bd2f-4af10145beda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ddcde102-2362-4541-982d-0420019dea81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# making training data \n",
    "# input (temp , rainfall  , humidity)\n",
    "inputs = np.array([[73,67,43],\n",
    "                  [91,88,64],\n",
    "                  [87,134,58],\n",
    "                  [102,43,37],\n",
    "                  [69,96,70]],dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4081da7-a7ea-48a4-a5c8-500a847e0e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets (apples and oranges)\n",
    "target = np.array([[56,70],\n",
    "                  [81,101],\n",
    "                  [119,133],\n",
    "                  [22,37],\n",
    "                  [103,119]],dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cace746e-5216-4baf-8f53-d24c54ffc029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 73.,  67.,  43.],\n",
      "        [ 91.,  88.,  64.],\n",
      "        [ 87., 134.,  58.],\n",
      "        [102.,  43.,  37.],\n",
      "        [ 69.,  96.,  70.]]) \n",
      "\n",
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "## convert it into a torch array\n",
    "inputs = torch.from_numpy(inputs)\n",
    "target = torch.from_numpy(target)\n",
    "\n",
    "print(inputs,'\\n')\n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c11757cd-819b-44b3-a3ad-572397dc079e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0761,  0.3807, -1.3061],\n",
      "        [-1.6619,  0.7192,  0.2594]], requires_grad=True)\n",
      "tensor([0.6157, 0.0969], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "## Weights and biaes \n",
    "w = torch.randn(2,3,requires_grad=True)\n",
    "b = torch.randn(2,requires_grad=True)\n",
    "\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b156cea3-598a-4546-9707-2a37553e7bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define model \n",
    "def model(x):\n",
    "    return x @ w.t() + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a865461-0442-42a9-b0db-b1635e7ce118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -35.5964,  -61.8761],\n",
      "        [ -56.3999,  -71.2380],\n",
      "        [ -30.7460,  -33.0633],\n",
      "        [ -39.1048, -128.8881],\n",
      "        [ -59.5159,  -27.3666]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## preiction \n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "43ecd224-0ad1-499a-9e70-b9488489a3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 56.,  70.],\n",
      "        [ 81., 101.],\n",
      "        [119., 133.],\n",
      "        [ 22.,  37.],\n",
      "        [103., 119.]])\n"
     ]
    }
   ],
   "source": [
    "# actual \n",
    "print(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0bc9f06e-c0fe-4559-a2a9-1bc4b03c241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## loss function MSE \n",
    "def MSE(actual , target):\n",
    "    diff = actual - target\n",
    "    return torch.sum(diff**2)/diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6657b128-cd11-4eef-8917-1c869f3cbd81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(20341.4082, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "## Error \n",
    "loss = MSE(target,preds)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c7ae450-3380-40d3-ab24-10f754a4b5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute gradient\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4dee058d-448d-4833-97cf-0e7863e3136a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0761,  0.3807, -1.3061],\n",
      "        [-1.6619,  0.7192,  0.2594]], requires_grad=True) \n",
      "\n",
      "tensor([[ -9932.8252, -11304.6318,  -7010.9004],\n",
      "        [-13353.6016, -13485.9014,  -8541.8203]])\n"
     ]
    }
   ],
   "source": [
    "print(w,'\\n')\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3b527655-a8de-447f-8a01-4c945a97d303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6157, 0.0969], requires_grad=True) \n",
      "\n",
      "tensor([-120.4726, -156.4864])\n"
     ]
    }
   ],
   "source": [
    "print(b,'\\n')\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1a584675-cfa0-4b89-8c89-410d36fe77a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Netural Network Using Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a96d2a1d-5d01-4d13-b095-a90da81f33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor , Lambda , Compose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "969efb07-b1b0-42c5-8e6e-402e80659dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26421880/26421880 [00:02<00:00, 9378389.29it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 29515/29515 [00:00<00:00, 231479.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4422102/4422102 [00:01<00:00, 4272263.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
      "\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5148/5148 [00:00<00:00, 8647287.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## downloading data from datasets\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root='data',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a6d72f11-f45a-45c3-86b5-4b418096df1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N ,C , H , W]: torch.Size([64, 1, 28, 28])\n",
      "Shape of y : torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64 \n",
    "## Create data loaders\n",
    "train_dataloader = DataLoader(training_data,batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data,batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print(\"Shape of X [N ,C , H , W]:\",X.shape)\n",
    "    print(\"Shape of y :\",y.shape , y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "032c229e-d4c4-4cf2-9045-302e63ae6be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "12ccaf14-9917-4db1-bd2a-8bfd6a75998f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9320b1cb-7465-461e-8a89-b75a152ffab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0511f2b5-d3a3-4e1f-9cd1-bdccafb14dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4efa2716-0304-4cc9-a508-2cfeb1542605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "86d28a9a-c3d0-476b-916d-9267688d6385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 2.293810  [    0/60000]\n",
      "loss: 2.278165  [ 6400/60000]\n",
      "loss: 2.255163  [12800/60000]\n",
      "loss: 2.250420  [19200/60000]\n",
      "loss: 2.238439  [25600/60000]\n",
      "loss: 2.194814  [32000/60000]\n",
      "loss: 2.216641  [38400/60000]\n",
      "loss: 2.169106  [44800/60000]\n",
      "loss: 2.173702  [51200/60000]\n",
      "loss: 2.137214  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 43.3%, Avg loss: 2.123531 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 2.138011  [    0/60000]\n",
      "loss: 2.118599  [ 6400/60000]\n",
      "loss: 2.055245  [12800/60000]\n",
      "loss: 2.075497  [19200/60000]\n",
      "loss: 2.021324  [25600/60000]\n",
      "loss: 1.948467  [32000/60000]\n",
      "loss: 1.983830  [38400/60000]\n",
      "loss: 1.891984  [44800/60000]\n",
      "loss: 1.906420  [51200/60000]\n",
      "loss: 1.824737  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 51.5%, Avg loss: 1.820021 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 1.862230  [    0/60000]\n",
      "loss: 1.819202  [ 6400/60000]\n",
      "loss: 1.700981  [12800/60000]\n",
      "loss: 1.747495  [19200/60000]\n",
      "loss: 1.644891  [25600/60000]\n",
      "loss: 1.592160  [32000/60000]\n",
      "loss: 1.618180  [38400/60000]\n",
      "loss: 1.522387  [44800/60000]\n",
      "loss: 1.552541  [51200/60000]\n",
      "loss: 1.447103  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 61.7%, Avg loss: 1.464280 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 1.536675  [    0/60000]\n",
      "loss: 1.495607  [ 6400/60000]\n",
      "loss: 1.353627  [12800/60000]\n",
      "loss: 1.430465  [19200/60000]\n",
      "loss: 1.325419  [25600/60000]\n",
      "loss: 1.314492  [32000/60000]\n",
      "loss: 1.337247  [38400/60000]\n",
      "loss: 1.263413  [44800/60000]\n",
      "loss: 1.298823  [51200/60000]\n",
      "loss: 1.207967  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 63.9%, Avg loss: 1.225104 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 1.301391  [    0/60000]\n",
      "loss: 1.278944  [ 6400/60000]\n",
      "loss: 1.122395  [12800/60000]\n",
      "loss: 1.231697  [19200/60000]\n",
      "loss: 1.119600  [25600/60000]\n",
      "loss: 1.134020  [32000/60000]\n",
      "loss: 1.164766  [38400/60000]\n",
      "loss: 1.100145  [44800/60000]\n",
      "loss: 1.139645  [51200/60000]\n",
      "loss: 1.064937  [57600/60000]\n",
      "Test Error: \n",
      " Accuracy: 65.3%, Avg loss: 1.074618 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_dataloader, model, loss_fn, optimizer)\n",
    "    test(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "863ae9d4-169b-4315-8993-8c811dc7984c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved PyTorch Model State to model.pth\n"
     ]
    }
   ],
   "source": [
    "#save model\n",
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a5d00523-abbb-4a76-ae9a-aac3e290f882",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model\n",
    "model = NeuralNetwork()\n",
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f4a19f25-3de4-4724-97e8-673fec02729a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
     ]
    }
   ],
   "source": [
    "## Prediction\n",
    "\n",
    "classes = [\n",
    "    \"T-shirt/top\",\n",
    "    \"Trouser\",\n",
    "    \"Pullover\",\n",
    "    \"Dress\",\n",
    "    \"Coat\",\n",
    "    \"Sandal\",\n",
    "    \"Shirt\",\n",
    "    \"Sneaker\",\n",
    "    \"Bag\",\n",
    "    \"Ankle boot\",\n",
    "]\n",
    "\n",
    "model.eval()\n",
    "x, y = test_data[0][0], test_data[0][1]\n",
    "with torch.no_grad():\n",
    "    pred = model(x)\n",
    "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
    "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba32b02-6bd0-4d29-992b-55ee9e923355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

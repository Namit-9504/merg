{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "309336fb",
   "metadata": {},
   "source": [
    "## Part 4 LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2233c63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Dense , Flatten , Conv2D , MaxPool2D\n",
    "from keras.models import Sequential\n",
    "from keras import utils\n",
    "from keras.datasets import mnist\n",
    "\n",
    "(X_train,y_train),(X_test,y_test)=mnist.load_data()\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0],28,28,1)\n",
    "X_test  = X_test.reshape(X_test.shape[0],28,28,1)\n",
    "\n",
    "X_train = X_train.astype(\"float32\")/255\n",
    "X_test = X_test.astype(\"float32\")/255\n",
    "\n",
    "y_train = utils.to_categorical(y_train,num_classes=10)\n",
    "y_test = utils.to_categorical(y_test,num_classes=10)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(6,kernel_size=(5,5),activation='relu',input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Conv2D(16,kernel_size=(5,5),activation='relu'))\n",
    "model.add(MaxPool2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(120,activation='relu'))\n",
    "model.add(Dense(84,activation='relu'))\n",
    "model.add(Dense(10,activation='softmax'))\n",
    "model.summary()\n",
    "model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=(\"Adam\"))\n",
    "model.fit(X_train,y_train,validation_data=(X_test,y_test),verbose=1,epochs=2,batch_size=128)\n",
    "Score= model.evaluate(X_test,y_test)\n",
    "print(\"Test Loss = \",Score[0])\n",
    "print(\"Test Accuracy = \",Score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e02ed6-6ded-465e-8b53-98142efedf7a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Alex Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4782de4d-8394-4ba5-8a44-dab393cd3a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "feb4e05d-0fed-4d5f-b8ab-3ea816fba410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Conv2D , BatchNormalization , Dense , MaxPool2D , Flatten , Dropout , Activation\n",
    "from keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad66ff5-c3d0-44cf-8350-04b481490f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5ec2ae-e997-4b2b-a5b6-636312d4a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn\n",
    "import tflearn.datasets.oxflower17 as  oxflower17\n",
    "from keras.utils import to_categorical\n",
    "X , y = oxflower17.load_data()\n",
    "\n",
    "X_train = X.astype('float32')/255.0\n",
    "y_train = to_categorical(y,num_classes=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be178122-4a9d-43b1-a20b-6e8867780a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020ac492-fc18-4c1c-b54b-9d2b86bb37f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st Convolutional Layer\n",
    "model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation before passing it to the next layer\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "\n",
    "# 3rd Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 4th Convolutional Layer\n",
    "model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# 5th Convolutional Layer\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "# Pooling\n",
    "model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='valid'))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "# Passing it to a dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# 1st Dense Layer\n",
    "model.add(Dense(4096, input_shape=(224*224*3,)))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout to prevent overfitting\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# 2nd Dense Layer\n",
    "model.add(Dense(4096))\n",
    "model.add(Activation('relu'))\n",
    "# Add Dropout\n",
    "model.add(Dropout(0.4))\n",
    "# Batch Normalisation\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Output Layer\n",
    "model.add(Dense(17))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1d38c9-7aea-4a0a-96c8-135a135828be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29eb9a7-ebb0-4645-b07d-8130957ec9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=1,validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0c96cf-8177-4004-9775-cda26798f81e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## VGG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "770da704-e90d-4580-aa99-ca78c92a8000",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tflearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260b00c1-660d-4e05-bc67-44110f623d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import keras,os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D , Flatten\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99fcab90-c5d1-4154-8778-b12f5dd6aa69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn.datasets.oxflower17 as oxflower17\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "x, y = oxflower17.load_data()\n",
    "\n",
    "x_train = x.astype('float32') / 255.0\n",
    "y_train = to_categorical(y, num_classes=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95bc3a6a-86fa-48c1-8ade-82ee32adc0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99728788-ef5e-4f30-bf2e-a2501ddbb673",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
    "model.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=4096,activation=\"relu\"))\n",
    "model.add(Dense(units=17, activation=\"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0065c6a-42f3-4b72-8ba3-3f2d3c828ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdc9421-509c-4bd8-a912-5729ed822a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=1,validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb67c777-e1e4-4eb6-b1bd-3876922749ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20de1ec9-0dca-4de8-b613-a1a2802d6974",
   "metadata": {},
   "source": [
    "### VGG Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bc97303d-a212-47f5-a927-09c6364bb69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install gdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1d9cf9e-2ccf-48e6-a90b-dd3ee02bc791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12jiQxJzYSYl3wnC8x5wHAhRzzJmmsCXP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?/export=download&id=12jiQxJzYSYl3wnC8x5wHAhRzzJmmsCXP\n",
      "To: /home/jovyan/work/test 1/catdog.zip\n",
      "100%|██████████| 9.09M/9.09M [00:00<00:00, 14.8MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'catdog.zip'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "url = \"https://drive.google.com/file/d/12jiQxJzYSYl3wnC8x5wHAhRzzJmmsCXP/view?usp=sharing\"\n",
    "file_id = url.split(\"/\")[-2]\n",
    "print(file_id)\n",
    "prefix = 'https://drive.google.com/uc?/export=download&id='\n",
    "gdown.download(prefix+file_id, \"catdog.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70d4fa99-781d-498e-8a62-8fdc51ba91b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  catdog.zip\n",
      "   creating: train/\n",
      "   creating: train/Cat/\n",
      "  inflating: train/Cat/0.jpg         \n",
      "  inflating: train/Cat/1.jpg         \n",
      "  inflating: train/Cat/2.jpg         \n",
      "  inflating: train/Cat/cat.2405.jpg  \n",
      "  inflating: train/Cat/cat.2406.jpg  \n",
      "  inflating: train/Cat/cat.2436.jpg  \n",
      "  inflating: train/Cat/cat.2437.jpg  \n",
      "  inflating: train/Cat/cat.2438.jpg  \n",
      "  inflating: train/Cat/cat.2439.jpg  \n",
      "  inflating: train/Cat/cat.2440.jpg  \n",
      "  inflating: train/Cat/cat.2441.jpg  \n",
      "  inflating: train/Cat/cat.2442.jpg  \n",
      "  inflating: train/Cat/cat.2443.jpg  \n",
      "  inflating: train/Cat/cat.2444.jpg  \n",
      "  inflating: train/Cat/cat.2445.jpg  \n",
      "  inflating: train/Cat/cat.2446.jpg  \n",
      "  inflating: train/Cat/cat.2447.jpg  \n",
      "  inflating: train/Cat/cat.2448.jpg  \n",
      "  inflating: train/Cat/cat.2449.jpg  \n",
      "  inflating: train/Cat/cat.2450.jpg  \n",
      "  inflating: train/Cat/cat.2451.jpg  \n",
      "  inflating: train/Cat/cat.2452.jpg  \n",
      "  inflating: train/Cat/cat.2453.jpg  \n",
      "  inflating: train/Cat/cat.2454.jpg  \n",
      "  inflating: train/Cat/cat.2455.jpg  \n",
      "  inflating: train/Cat/cat.2456.jpg  \n",
      "  inflating: train/Cat/cat.2457.jpg  \n",
      "  inflating: train/Cat/cat.2458.jpg  \n",
      "  inflating: train/Cat/cat.2459.jpg  \n",
      "  inflating: train/Cat/cat.2460.jpg  \n",
      "  inflating: train/Cat/cat.2461.jpg  \n",
      "  inflating: train/Cat/cat.2462.jpg  \n",
      "  inflating: train/Cat/cat.2463.jpg  \n",
      "  inflating: train/Cat/cat.2464.jpg  \n",
      "  inflating: train/Cat/cat.855.jpg   \n",
      "  inflating: train/Cat/cat.856.jpg   \n",
      "  inflating: train/Cat/cat.857.jpg   \n",
      "  inflating: train/Cat/cat.858.jpg   \n",
      "  inflating: train/Cat/cat.859.jpg   \n",
      "  inflating: train/Cat/cat.86.jpg    \n",
      "  inflating: train/Cat/cat.860.jpg   \n",
      "  inflating: train/Cat/cat.861.jpg   \n",
      "  inflating: train/Cat/cat.862.jpg   \n",
      "  inflating: train/Cat/cat.863.jpg   \n",
      "  inflating: train/Cat/cat.864.jpg   \n",
      "  inflating: train/Cat/cat.865.jpg   \n",
      "  inflating: train/Cat/cat.866.jpg   \n",
      "  inflating: train/Cat/cat.867.jpg   \n",
      "  inflating: train/Cat/cat.868.jpg   \n",
      "  inflating: train/Cat/cat.869.jpg   \n",
      "  inflating: train/Cat/cat.87.jpg    \n",
      "  inflating: train/Cat/cat.870.jpg   \n",
      "  inflating: train/Cat/cat.871.jpg   \n",
      "  inflating: train/Cat/cat.872.jpg   \n",
      "  inflating: train/Cat/cat.873.jpg   \n",
      "  inflating: train/Cat/cat.874.jpg   \n",
      "  inflating: train/Cat/cat.875.jpg   \n",
      "  inflating: train/Cat/cat.876.jpg   \n",
      "  inflating: train/Cat/cat.877.jpg   \n",
      "  inflating: train/Cat/cat.878.jpg   \n",
      "  inflating: train/Cat/cat.879.jpg   \n",
      "  inflating: train/Cat/cat.88.jpg    \n",
      "  inflating: train/Cat/cat.880.jpg   \n",
      "  inflating: train/Cat/cat.881.jpg   \n",
      "  inflating: train/Cat/cat.882.jpg   \n",
      "  inflating: train/Cat/cat.883.jpg   \n",
      "  inflating: train/Cat/cat.884.jpg   \n",
      "  inflating: train/Cat/cat.885.jpg   \n",
      "  inflating: train/Cat/cat.886.jpg   \n",
      "  inflating: train/Cat/cat.887.jpg   \n",
      "  inflating: train/Cat/cat.888.jpg   \n",
      "  inflating: train/Cat/cat.889.jpg   \n",
      "  inflating: train/Cat/cat.89.jpg    \n",
      "  inflating: train/Cat/cat.890.jpg   \n",
      "  inflating: train/Cat/cat.891.jpg   \n",
      "  inflating: train/Cat/cat.892.jpg   \n",
      "  inflating: train/Cat/cat.893.jpg   \n",
      "  inflating: train/Cat/cat.894.jpg   \n",
      "  inflating: train/Cat/cat.895.jpg   \n",
      "  inflating: train/Cat/cat.896.jpg   \n",
      "  inflating: train/Cat/cat.897.jpg   \n",
      "  inflating: train/Cat/cat.898.jpg   \n",
      "  inflating: train/Cat/cat.899.jpg   \n",
      "  inflating: train/Cat/cat.9.jpg     \n",
      "  inflating: train/Cat/cat.90.jpg    \n",
      "  inflating: train/Cat/cat.900.jpg   \n",
      "  inflating: train/Cat/cat.901.jpg   \n",
      "  inflating: train/Cat/cat.902.jpg   \n",
      "  inflating: train/Cat/cat.903.jpg   \n",
      "  inflating: train/Cat/cat.904.jpg   \n",
      "  inflating: train/Cat/cat.905.jpg   \n",
      "  inflating: train/Cat/cat.906.jpg   \n",
      "  inflating: train/Cat/cat.907.jpg   \n",
      "  inflating: train/Cat/cat.908.jpg   \n",
      "  inflating: train/Cat/cat.909.jpg   \n",
      "  inflating: train/Cat/cat.91.jpg    \n",
      "  inflating: train/Cat/cat.910.jpg   \n",
      "  inflating: train/Cat/cat.911.jpg   \n",
      "  inflating: train/Cat/cat.912.jpg   \n",
      "  inflating: train/Cat/cat.913.jpg   \n",
      "  inflating: train/Cat/cat.914.jpg   \n",
      "  inflating: train/Cat/cat.915.jpg   \n",
      "  inflating: train/Cat/cat.916.jpg   \n",
      "  inflating: train/Cat/cat.917.jpg   \n",
      "  inflating: train/Cat/cat.918.jpg   \n",
      "  inflating: train/Cat/cat.919.jpg   \n",
      "  inflating: train/Cat/cat.92.jpg    \n",
      "  inflating: train/Cat/cat.920.jpg   \n",
      "  inflating: train/Cat/cat.93.jpg    \n",
      "  inflating: train/Cat/cat.94.jpg    \n",
      "  inflating: train/Cat/cat.946.jpg   \n",
      "  inflating: train/Cat/cat.947.jpg   \n",
      "  inflating: train/Cat/cat.948.jpg   \n",
      "  inflating: train/Cat/cat.949.jpg   \n",
      "  inflating: train/Cat/cat.95.jpg    \n",
      "  inflating: train/Cat/cat.950.jpg   \n",
      "  inflating: train/Cat/cat.951.jpg   \n",
      "  inflating: train/Cat/cat.952.jpg   \n",
      "  inflating: train/Cat/cat.953.jpg   \n",
      "  inflating: train/Cat/cat.954.jpg   \n",
      "  inflating: train/Cat/cat.955.jpg   \n",
      "  inflating: train/Cat/cat.956.jpg   \n",
      "  inflating: train/Cat/cat.957.jpg   \n",
      "  inflating: train/Cat/cat.958.jpg   \n",
      "  inflating: train/Cat/cat.959.jpg   \n",
      "  inflating: train/Cat/cat.96.jpg    \n",
      "  inflating: train/Cat/cat.960.jpg   \n",
      "  inflating: train/Cat/cat.961.jpg   \n",
      "  inflating: train/Cat/cat.962.jpg   \n",
      "  inflating: train/Cat/cat.963.jpg   \n",
      "  inflating: train/Cat/cat.964.jpg   \n",
      "  inflating: train/Cat/cat.965.jpg   \n",
      "  inflating: train/Cat/cat.966.jpg   \n",
      "  inflating: train/Cat/cat.967.jpg   \n",
      "  inflating: train/Cat/cat.968.jpg   \n",
      "  inflating: train/Cat/cat.969.jpg   \n",
      "  inflating: train/Cat/cat.97.jpg    \n",
      "  inflating: train/Cat/cat.970.jpg   \n",
      "  inflating: train/Cat/cat.971.jpg   \n",
      "  inflating: train/Cat/cat.972.jpg   \n",
      "  inflating: train/Cat/cat.973.jpg   \n",
      "  inflating: train/Cat/cat.974.jpg   \n",
      "  inflating: train/Cat/cat.975.jpg   \n",
      "  inflating: train/Cat/cat.976.jpg   \n",
      "  inflating: train/Cat/cat.977.jpg   \n",
      "  inflating: train/Cat/cat.978.jpg   \n",
      "  inflating: train/Cat/cat.979.jpg   \n",
      "  inflating: train/Cat/cat.98.jpg    \n",
      "  inflating: train/Cat/cat.980.jpg   \n",
      "  inflating: train/Cat/cat.981.jpg   \n",
      "  inflating: train/Cat/cat.982.jpg   \n",
      "  inflating: train/Cat/cat.983.jpg   \n",
      "  inflating: train/Cat/cat.984.jpg   \n",
      "  inflating: train/Cat/cat.985.jpg   \n",
      "  inflating: train/Cat/cat.986.jpg   \n",
      "  inflating: train/Cat/cat.987.jpg   \n",
      "  inflating: train/Cat/cat.988.jpg   \n",
      "  inflating: train/Cat/cat.989.jpg   \n",
      "  inflating: train/Cat/cat.99.jpg    \n",
      "  inflating: train/Cat/cat.990.jpg   \n",
      "  inflating: train/Cat/cat.991.jpg   \n",
      "  inflating: train/Cat/cat.992.jpg   \n",
      "  inflating: train/Cat/cat.993.jpg   \n",
      "  inflating: train/Cat/cat.994.jpg   \n",
      "  inflating: train/Cat/cat.995.jpg   \n",
      "  inflating: train/Cat/cat.996.jpg   \n",
      "  inflating: train/Cat/cat.997.jpg   \n",
      "  inflating: train/Cat/cat.998.jpg   \n",
      "  inflating: train/Cat/cat.999.jpg   \n",
      "   creating: train/Dog/\n",
      "  inflating: train/Dog/10493.jpg     \n",
      "  inflating: train/Dog/11785.jpg     \n",
      "  inflating: train/Dog/9839.jpg      \n",
      "  inflating: train/Dog/dog.2432.jpg  \n",
      "  inflating: train/Dog/dog.2433.jpg  \n",
      "  inflating: train/Dog/dog.2434.jpg  \n",
      "  inflating: train/Dog/dog.2435.jpg  \n",
      "  inflating: train/Dog/dog.2436.jpg  \n",
      "  inflating: train/Dog/dog.2437.jpg  \n",
      "  inflating: train/Dog/dog.2438.jpg  \n",
      "  inflating: train/Dog/dog.2439.jpg  \n",
      "  inflating: train/Dog/dog.2440.jpg  \n",
      "  inflating: train/Dog/dog.2441.jpg  \n",
      "  inflating: train/Dog/dog.2442.jpg  \n",
      "  inflating: train/Dog/dog.2443.jpg  \n",
      "  inflating: train/Dog/dog.2444.jpg  \n",
      "  inflating: train/Dog/dog.2445.jpg  \n",
      "  inflating: train/Dog/dog.2446.jpg  \n",
      "  inflating: train/Dog/dog.2447.jpg  \n",
      "  inflating: train/Dog/dog.2448.jpg  \n",
      "  inflating: train/Dog/dog.2449.jpg  \n",
      "  inflating: train/Dog/dog.2450.jpg  \n",
      "  inflating: train/Dog/dog.2451.jpg  \n",
      "  inflating: train/Dog/dog.2452.jpg  \n",
      "  inflating: train/Dog/dog.2453.jpg  \n",
      "  inflating: train/Dog/dog.2454.jpg  \n",
      "  inflating: train/Dog/dog.2455.jpg  \n",
      "  inflating: train/Dog/dog.2456.jpg  \n",
      "  inflating: train/Dog/dog.2457.jpg  \n",
      "  inflating: train/Dog/dog.2458.jpg  \n",
      "  inflating: train/Dog/dog.2459.jpg  \n",
      "  inflating: train/Dog/dog.2460.jpg  \n",
      "  inflating: train/Dog/dog.2461.jpg  \n",
      "  inflating: train/Dog/dog.844.jpg   \n",
      "  inflating: train/Dog/dog.845.jpg   \n",
      "  inflating: train/Dog/dog.846.jpg   \n",
      "  inflating: train/Dog/dog.847.jpg   \n",
      "  inflating: train/Dog/dog.848.jpg   \n",
      "  inflating: train/Dog/dog.849.jpg   \n",
      "  inflating: train/Dog/dog.85.jpg    \n",
      "  inflating: train/Dog/dog.850.jpg   \n",
      "  inflating: train/Dog/dog.851.jpg   \n",
      "  inflating: train/Dog/dog.852.jpg   \n",
      "  inflating: train/Dog/dog.853.jpg   \n",
      "  inflating: train/Dog/dog.854.jpg   \n",
      "  inflating: train/Dog/dog.855.jpg   \n",
      "  inflating: train/Dog/dog.856.jpg   \n",
      "  inflating: train/Dog/dog.857.jpg   \n",
      "  inflating: train/Dog/dog.858.jpg   \n",
      "  inflating: train/Dog/dog.859.jpg   \n",
      "  inflating: train/Dog/dog.86.jpg    \n",
      "  inflating: train/Dog/dog.860.jpg   \n",
      "  inflating: train/Dog/dog.861.jpg   \n",
      "  inflating: train/Dog/dog.862.jpg   \n",
      "  inflating: train/Dog/dog.863.jpg   \n",
      "  inflating: train/Dog/dog.864.jpg   \n",
      "  inflating: train/Dog/dog.865.jpg   \n",
      "  inflating: train/Dog/dog.866.jpg   \n",
      "  inflating: train/Dog/dog.867.jpg   \n",
      "  inflating: train/Dog/dog.868.jpg   \n",
      "  inflating: train/Dog/dog.869.jpg   \n",
      "  inflating: train/Dog/dog.87.jpg    \n",
      "  inflating: train/Dog/dog.870.jpg   \n",
      "  inflating: train/Dog/dog.871.jpg   \n",
      "  inflating: train/Dog/dog.872.jpg   \n",
      "  inflating: train/Dog/dog.873.jpg   \n",
      "  inflating: train/Dog/dog.874.jpg   \n",
      "  inflating: train/Dog/dog.875.jpg   \n",
      "  inflating: train/Dog/dog.876.jpg   \n",
      "  inflating: train/Dog/dog.877.jpg   \n",
      "  inflating: train/Dog/dog.878.jpg   \n",
      "  inflating: train/Dog/dog.879.jpg   \n",
      "  inflating: train/Dog/dog.88.jpg    \n",
      "  inflating: train/Dog/dog.880.jpg   \n",
      "  inflating: train/Dog/dog.881.jpg   \n",
      "  inflating: train/Dog/dog.882.jpg   \n",
      "  inflating: train/Dog/dog.883.jpg   \n",
      "  inflating: train/Dog/dog.884.jpg   \n",
      "  inflating: train/Dog/dog.885.jpg   \n",
      "  inflating: train/Dog/dog.886.jpg   \n",
      "  inflating: train/Dog/dog.887.jpg   \n",
      "  inflating: train/Dog/dog.888.jpg   \n",
      "  inflating: train/Dog/dog.889.jpg   \n",
      "  inflating: train/Dog/dog.89.jpg    \n",
      "  inflating: train/Dog/dog.890.jpg   \n",
      "  inflating: train/Dog/dog.891.jpg   \n",
      "  inflating: train/Dog/dog.892.jpg   \n",
      "  inflating: train/Dog/dog.893.jpg   \n",
      "  inflating: train/Dog/dog.894.jpg   \n",
      "  inflating: train/Dog/dog.895.jpg   \n",
      "  inflating: train/Dog/dog.896.jpg   \n",
      "  inflating: train/Dog/dog.897.jpg   \n",
      "  inflating: train/Dog/dog.898.jpg   \n",
      "  inflating: train/Dog/dog.9.jpg     \n",
      "  inflating: train/Dog/dog.90.jpg    \n",
      "  inflating: train/Dog/dog.91.jpg    \n",
      "  inflating: train/Dog/dog.92.jpg    \n",
      "  inflating: train/Dog/dog.93.jpg    \n",
      "  inflating: train/Dog/dog.936.jpg   \n",
      "  inflating: train/Dog/dog.937.jpg   \n",
      "  inflating: train/Dog/dog.938.jpg   \n",
      "  inflating: train/Dog/dog.939.jpg   \n",
      "  inflating: train/Dog/dog.94.jpg    \n",
      "  inflating: train/Dog/dog.940.jpg   \n",
      "  inflating: train/Dog/dog.941.jpg   \n",
      "  inflating: train/Dog/dog.942.jpg   \n",
      "  inflating: train/Dog/dog.943.jpg   \n",
      "  inflating: train/Dog/dog.944.jpg   \n",
      "  inflating: train/Dog/dog.945.jpg   \n",
      "  inflating: train/Dog/dog.946.jpg   \n",
      "  inflating: train/Dog/dog.947.jpg   \n",
      "  inflating: train/Dog/dog.948.jpg   \n",
      "  inflating: train/Dog/dog.949.jpg   \n",
      "  inflating: train/Dog/dog.95.jpg    \n",
      "  inflating: train/Dog/dog.950.jpg   \n",
      "  inflating: train/Dog/dog.951.jpg   \n",
      "  inflating: train/Dog/dog.952.jpg   \n",
      "  inflating: train/Dog/dog.953.jpg   \n",
      "  inflating: train/Dog/dog.954.jpg   \n",
      "  inflating: train/Dog/dog.955.jpg   \n",
      "  inflating: train/Dog/dog.956.jpg   \n",
      "  inflating: train/Dog/dog.957.jpg   \n",
      "  inflating: train/Dog/dog.958.jpg   \n",
      "  inflating: train/Dog/dog.959.jpg   \n",
      "  inflating: train/Dog/dog.96.jpg    \n",
      "  inflating: train/Dog/dog.960.jpg   \n",
      "  inflating: train/Dog/dog.961.jpg   \n",
      "  inflating: train/Dog/dog.962.jpg   \n",
      "  inflating: train/Dog/dog.963.jpg   \n",
      "  inflating: train/Dog/dog.964.jpg   \n",
      "  inflating: train/Dog/dog.965.jpg   \n",
      "  inflating: train/Dog/dog.966.jpg   \n",
      "  inflating: train/Dog/dog.967.jpg   \n",
      "  inflating: train/Dog/dog.968.jpg   \n",
      "  inflating: train/Dog/dog.969.jpg   \n",
      "  inflating: train/Dog/dog.97.jpg    \n",
      "  inflating: train/Dog/dog.970.jpg   \n",
      "  inflating: train/Dog/dog.971.jpg   \n",
      "  inflating: train/Dog/dog.972.jpg   \n",
      "  inflating: train/Dog/dog.973.jpg   \n",
      "  inflating: train/Dog/dog.974.jpg   \n",
      "  inflating: train/Dog/dog.975.jpg   \n",
      "  inflating: train/Dog/dog.976.jpg   \n",
      "  inflating: train/Dog/dog.977.jpg   \n",
      "  inflating: train/Dog/dog.978.jpg   \n",
      "  inflating: train/Dog/dog.979.jpg   \n",
      "  inflating: train/Dog/dog.98.jpg    \n",
      "  inflating: train/Dog/dog.980.jpg   \n",
      "  inflating: train/Dog/dog.981.jpg   \n",
      "  inflating: train/Dog/dog.982.jpg   \n",
      "  inflating: train/Dog/dog.983.jpg   \n",
      "  inflating: train/Dog/dog.984.jpg   \n",
      "  inflating: train/Dog/dog.985.jpg   \n",
      "  inflating: train/Dog/dog.986.jpg   \n",
      "  inflating: train/Dog/dog.987.jpg   \n",
      "  inflating: train/Dog/dog.988.jpg   \n",
      "  inflating: train/Dog/dog.989.jpg   \n",
      "  inflating: train/Dog/dog.99.jpg    \n",
      "  inflating: train/Dog/dog.990.jpg   \n",
      "  inflating: train/Dog/dog.991.jpg   \n",
      "  inflating: train/Dog/dog.992.jpg   \n",
      "  inflating: train/Dog/dog.993.jpg   \n",
      "  inflating: train/Dog/dog.994.jpg   \n",
      "  inflating: train/Dog/dog.995.jpg   \n",
      "  inflating: train/Dog/dog.996.jpg   \n",
      "  inflating: train/Dog/dog.997.jpg   \n",
      "  inflating: train/Dog/dog.998.jpg   \n",
      "  inflating: train/Dog/dog.999.jpg   \n",
      "   creating: validation/\n",
      "   creating: validation/Cat/\n",
      "  inflating: validation/Cat/cat.2407.jpg  \n",
      "  inflating: validation/Cat/cat.2408.jpg  \n",
      "  inflating: validation/Cat/cat.2409.jpg  \n",
      "  inflating: validation/Cat/cat.2410.jpg  \n",
      "  inflating: validation/Cat/cat.2411.jpg  \n",
      "  inflating: validation/Cat/cat.2412.jpg  \n",
      "  inflating: validation/Cat/cat.2413.jpg  \n",
      "  inflating: validation/Cat/cat.2414.jpg  \n",
      "  inflating: validation/Cat/cat.2415.jpg  \n",
      "  inflating: validation/Cat/cat.2416.jpg  \n",
      "  inflating: validation/Cat/cat.2417.jpg  \n",
      "  inflating: validation/Cat/cat.2418.jpg  \n",
      "  inflating: validation/Cat/cat.2419.jpg  \n",
      "  inflating: validation/Cat/cat.2420.jpg  \n",
      "  inflating: validation/Cat/cat.2421.jpg  \n",
      "  inflating: validation/Cat/cat.2422.jpg  \n",
      "  inflating: validation/Cat/cat.2423.jpg  \n",
      "  inflating: validation/Cat/cat.2424.jpg  \n",
      "  inflating: validation/Cat/cat.2425.jpg  \n",
      "  inflating: validation/Cat/cat.2426.jpg  \n",
      "  inflating: validation/Cat/cat.2427.jpg  \n",
      "  inflating: validation/Cat/cat.2428.jpg  \n",
      "  inflating: validation/Cat/cat.2429.jpg  \n",
      "  inflating: validation/Cat/cat.2430.jpg  \n",
      "  inflating: validation/Cat/cat.2431.jpg  \n",
      "  inflating: validation/Cat/cat.2432.jpg  \n",
      "  inflating: validation/Cat/cat.2433.jpg  \n",
      "  inflating: validation/Cat/cat.2434.jpg  \n",
      "  inflating: validation/Cat/cat.2435.jpg  \n",
      "   creating: validation/Dog/\n",
      "  inflating: validation/Dog/dog.2402.jpg  \n",
      "  inflating: validation/Dog/dog.2403.jpg  \n",
      "  inflating: validation/Dog/dog.2404.jpg  \n",
      "  inflating: validation/Dog/dog.2405.jpg  \n",
      "  inflating: validation/Dog/dog.2406.jpg  \n",
      "  inflating: validation/Dog/dog.2407.jpg  \n",
      "  inflating: validation/Dog/dog.2408.jpg  \n",
      "  inflating: validation/Dog/dog.2409.jpg  \n",
      "  inflating: validation/Dog/dog.2410.jpg  \n",
      "  inflating: validation/Dog/dog.2411.jpg  \n",
      "  inflating: validation/Dog/dog.2412.jpg  \n",
      "  inflating: validation/Dog/dog.2413.jpg  \n",
      "  inflating: validation/Dog/dog.2414.jpg  \n",
      "  inflating: validation/Dog/dog.2415.jpg  \n",
      "  inflating: validation/Dog/dog.2416.jpg  \n",
      "  inflating: validation/Dog/dog.2417.jpg  \n",
      "  inflating: validation/Dog/dog.2418.jpg  \n",
      "  inflating: validation/Dog/dog.2419.jpg  \n",
      "  inflating: validation/Dog/dog.2420.jpg  \n",
      "  inflating: validation/Dog/dog.2421.jpg  \n",
      "  inflating: validation/Dog/dog.2422.jpg  \n",
      "  inflating: validation/Dog/dog.2423.jpg  \n",
      "  inflating: validation/Dog/dog.2424.jpg  \n",
      "  inflating: validation/Dog/dog.2425.jpg  \n",
      "  inflating: validation/Dog/dog.2426.jpg  \n",
      "  inflating: validation/Dog/dog.2427.jpg  \n",
      "  inflating: validation/Dog/dog.2428.jpg  \n",
      "  inflating: validation/Dog/dog.2429.jpg  \n",
      "  inflating: validation/Dog/dog.2430.jpg  \n",
      "  inflating: validation/Dog/dog.2431.jpg  \n"
     ]
    }
   ],
   "source": [
    "!unzip catdog.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ec81f41-1465-4d5a-9dcd-965ae718bca2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 10:01:15.037435: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-02 10:01:15.668465: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-02 10:01:15.668526: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-02 10:01:15.672730: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-02 10:01:16.045253: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-02 10:01:16.048336: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-02 10:01:18.139239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense , Flatten , Conv2D , MaxPooling2D,Dropout\n",
    "from keras.models import Sequential \n",
    "from keras.preprocessing.image import ImageDataGenerator ## It is used to generate numpy arrays of images\n",
    "from keras.applications.vgg16 import VGG16 , preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a85d5f2-facb-490a-8cf5-b2694836d8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the path \n",
    "train_data_dir = 'train'\n",
    "validation_data_dir = 'validation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4178ed25-5830-41bd-8591-88d482782ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_samples = 2000\n",
    "num_validation_samples = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ab4f066-c3ab-4038-8e1d-5c702ff04bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5 \n",
    "batch_size = 16 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b00add6-d35f-4b0d-b0f2-cdcbb48e5f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet',include_top=False,input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "22f72c30-af50-48e0-9095-239cc8e1a208",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e83815a2-f0e7-4927-9235-7a9b5449e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(base_model)\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d45a4a6-c107-4d01-a6b2-a64ec7ea7be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af7b2b10-fcdd-4bc9-8649-eff01cf1f603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 337 images belonging to 2 classes.\n",
      "Found 59 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator=train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    ")\n",
    "validation_generator=validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(224,224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aa4119e5-a3c8-4074-9ff7-ff8fbcb8b96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 22/125 [====>.........................] - ETA: 1:11 - loss: 0.9052 - accuracy: 0.9822WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 625 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "125/125 [==============================] - 18s 141ms/step - loss: 0.9052 - accuracy: 0.9822 - val_loss: 1.6385 - val_accuracy: 0.9831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fb4347d60e0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_validation_samples // batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d6638c0-3ed1-4713-b054-c613d2e41f02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "model.save('dog_cat_classifier.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a010447-e44d-4eb9-bb62-09b6baddf64a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Resnet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e295a67d-37e5-4fa0-8ba4-8c8e7dc012d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, BatchNormalization, Activation, Add, AveragePooling2D, Flatten, Dense\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f643afe7-e797-46bc-8158-065654705f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "import tflearn.datasets.oxflower17 as oxflower17\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "x, y = oxflower17.load_data()\n",
    "\n",
    "x_train = x.astype('float32') / 255.0\n",
    "y_train = to_categorical(y, num_classes=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c36e47-98e3-4aad-be4c-d68133b31e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1103e4c-8950-452f-b592-673031bea1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Residual block\n",
    "def residual_block(x, filters, downsample=False):\n",
    "    strides = (2, 2) if downsample else (1, 1)\n",
    "\n",
    "    # First convolutional layer of the block\n",
    "    y = Conv2D(filters, kernel_size=(3, 3), strides=strides, padding='same')(x)\n",
    "    y = BatchNormalization()(y)\n",
    "    y = Activation('relu')(y)\n",
    "\n",
    "    # Second convolutional layer of the block\n",
    "    y = Conv2D(filters, kernel_size=(3, 3), strides=(1, 1), padding='same')(y)\n",
    "    y = BatchNormalization()(y)\n",
    "\n",
    "    # Skip connection if downsample or number of filters change\n",
    "    if downsample:\n",
    "        x = Conv2D(filters, kernel_size=(1, 1), strides=(2, 2), padding='same')(x)\n",
    "\n",
    "    # Add skip connection\n",
    "    y = Add()([x, y])\n",
    "    y = Activation('relu')(y)\n",
    "    return y\n",
    "\n",
    "# Build the ResNet model\n",
    "def resnet(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape)\n",
    "\n",
    "    # Initial convolutional layer\n",
    "    x = Conv2D(16, kernel_size=(3, 3), strides=(1, 1), padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "\n",
    "    # Residual blocks\n",
    "    x = residual_block(x, filters=16)\n",
    "    x = residual_block(x, filters=16)\n",
    "    x = residual_block(x, filters=32, downsample=True)\n",
    "    x = residual_block(x, filters=32)\n",
    "    x = residual_block(x, filters=64, downsample=True)\n",
    "    x = residual_block(x, filters=64)\n",
    "\n",
    "    # Average pooling and output layer\n",
    "    x = AveragePooling2D(pool_size=(8, 8))(x)\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cce5b6-2ef2-4e7a-afcb-6789a55abe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet(input_shape=(224, 224, 3), num_classes=17)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=1,validation_split=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af47a9dd-d13c-4b0a-996f-5c44465e1ea2",
   "metadata": {},
   "source": [
    "### Pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d6c40-dd04-46a3-93e1-662555dfb312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the data from g drive\n",
    "\n",
    "import gdown\n",
    "url = \"https://drive.google.com/file/d/12jiQxJzYSYl3wnC8x5wHAhRzzJmmsCXP/view?usp=sharing\"\n",
    "file_id = url.split(\"/\")[-2]\n",
    "print(file_id)\n",
    "prefix = 'https://drive.google.com/uc?/export=download&id='\n",
    "gdown.download(prefix+file_id, \"catdog.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b6e03-c0dc-42cc-8611-08df93012f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip catdog.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59849072-5cec-483f-9b77-e129be3e1178",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "\n",
    "# Set the path to your training and validation data\n",
    "train_data_dir = '/content/train'\n",
    "validation_data_dir = '/content/validation'\n",
    "\n",
    "# Set the number of training and validation samples\n",
    "num_train_samples = 2000\n",
    "num_validation_samples = 800\n",
    "\n",
    "# Set the number of epochs and batch size\n",
    "epochs = 5\n",
    "batch_size = 16\n",
    "\n",
    "# Load the VGG16 model without the top layer\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Freeze the base model layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create a new model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the base model as a layer\n",
    "model.add(base_model)\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Preprocess the training and validation data\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=num_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=num_validation_samples // batch_size)\n",
    "\n",
    "# Save the trained model\n",
    "model.save('dog_cat_classifier.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "709d6f0e-8810-4722-88b6-4f8e5f53a253",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Inception Net "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c787e1cc-2426-413a-92c8-793a61194037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-02 12:33:56.476301: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-02 12:33:56.539616: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-10-02 12:33:56.539683: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-10-02 12:33:56.539721: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-10-02 12:33:56.549698: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-10-02 12:33:56.550729: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-10-02 12:33:57.992081: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, concatenate, Flatten, Dense, AveragePooling2D\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9197aaaa-3b97-4c4b-af02-4857c54e8e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Data\n",
    "import tflearn.datasets.oxflower17 as oxflower17\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "x, y = oxflower17.load_data()\n",
    "\n",
    "x_train = x.astype('float32') / 255.0\n",
    "y_train = to_categorical(y, num_classes=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c383fd0a-2aed-4152-8459-336be20e28c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce76fc25-9621-4d57-8522-25ca88fe84d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inception block\n",
    "def inception_block(x, filters):\n",
    "    tower_1 = Conv2D(filters[0], (1, 1), padding='same', activation='relu')(x)\n",
    "    tower_1 = Conv2D(filters[1], (3, 3), padding='same', activation='relu')(tower_1)\n",
    "\n",
    "    tower_2 = Conv2D(filters[2], (1, 1), padding='same', activation='relu')(x)\n",
    "    tower_2 = Conv2D(filters[3], (5, 5), padding='same', activation='relu')(tower_2)\n",
    "\n",
    "    tower_3 = MaxPooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    tower_3 = Conv2D(filters[4], (1, 1), padding='same', activation='relu')(tower_3)\n",
    "\n",
    "    output = concatenate([tower_1, tower_2, tower_3], axis=3)\n",
    "    return output\n",
    "\n",
    "# Build the Inception model\n",
    "def inception(input_shape, num_classes):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = inception_block(x, filters=[64, 96, 128, 16, 32])\n",
    "    x = inception_block(x, filters=[128, 128, 192, 32, 96])\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = inception_block(x, filters=[192, 96, 208, 16, 48])\n",
    "    x = inception_block(x, filters=[160, 112, 224, 24, 64])\n",
    "    x = inception_block(x, filters=[128, 128, 256, 24, 64])\n",
    "    x = inception_block(x, filters=[112, 144, 288, 32, 64])\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = inception_block(x, filters=[256, 160, 320, 32, 128])\n",
    "    x = inception_block(x, filters=[256, 160, 320, 32, 128])\n",
    "    x = inception_block(x, filters=[384, 192, 384, 48, 128])\n",
    "\n",
    "    x = AveragePooling2D((4, 4))(x)\n",
    "    x = Flatten()(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc1948a-708a-4858-b365-7837ff2c8c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Inception model\n",
    "model = inception(input_shape=(224, 224, 3), num_classes=17)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print a summary of the model\n",
    "model.summary()\n",
    "\n",
    "# Train\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=1,validation_split=0.2, shuffle=Tru"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9214e38-1443-4852-a90a-87d1da93f4a9",
   "metadata": {},
   "source": [
    "## Predefined "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f300d84b-4083-4e22-90ea-65d93d110bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3 ,preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense , Dropout , Flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a3ae4bb-1e0a-431e-8098-2da9726e96dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "87910968/87910968 [==============================] - 7s 0us/step\n"
     ]
    }
   ],
   "source": [
    "Base_model = InceptionV3(weights='imagenet',include_top=False,input_shape=(224,224,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0730b057-9c75-4dca-89e0-cdf3748309df",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in Base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca4fc7ee-29b1-4998-8ba3-8656893d431d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Base_model)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e2ba7a3e-e2ad-4b6e-b74e-8d126adf1292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 337 images belonging to 2 classes.\n",
      "Found 59 images belonging to 2 classes.\n",
      "Epoch 1/5\n",
      " 22/125 [====>.........................] - ETA: 27s - loss: 4.9197 - accuracy: 0.8516WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 625 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 50 batches). You may need to use the repeat() function when building your dataset.\n",
      "125/125 [==============================] - 14s 69ms/step - loss: 4.9197 - accuracy: 0.8516 - val_loss: 0.7259 - val_accuracy: 0.9661\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:3079: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "validation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_genretor = train_datagen.flow_from_directory('train',target_size=(224,224),batch_size=16,class_mode='binary')\n",
    "validation_genretor = validation_datagen.flow_from_directory('validation',target_size=(224,224),batch_size=16,class_mode='binary')\n",
    "\n",
    "\n",
    "\n",
    "model.fit(train_genretor,\n",
    "          epochs=5,\n",
    "          steps_per_epoch=2000 // 16 ,\n",
    "          validation_data=validation_genretor ,\n",
    "          validation_steps=800 // 16 ,  )\n",
    "\n",
    "model.save('1dog_cat_classification.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b3dbfa-642d-4361-a979-e4b89eeb19a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
